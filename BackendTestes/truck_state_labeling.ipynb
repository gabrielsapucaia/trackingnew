{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline de Rotulagem de Estados Operacionais de Caminh√µes\n",
        "\n",
        "Este notebook implementa um pipeline completo para identificar e rotular estados operacionais quando a velocidade est√° pr√≥xima de zero, cruzando dados de velocidade, acelera√ß√£o linear, orienta√ß√£o e outros sinais dispon√≠veis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 0: Configura√ß√£o e Par√¢metros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Importar utilit√°rios\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "from labeling_utils import (\n",
        "    get_db_connection, discover_schema, check_data_availability,\n",
        "    query_data, find_stop_segments, find_moving_segments,\n",
        "    merge_basculamento_segments, extract_features, classify_stop_segment\n",
        ")\n",
        "\n",
        "# Configura√ß√£o de visualiza√ß√£o\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PAR√ÇMETROS AJUST√ÅVEIS\n",
        "# ============================================================\n",
        "\n",
        "V_STOP = 0.5           # km/h - threshold para considerar parado\n",
        "MIN_STOP_SEC = 30      # dura√ß√£o m√≠nima de parada (segundos)\n",
        "GAP_SEC = 5            # toler√¢ncia para buracos entre segmentos (segundos)\n",
        "TH_CONF = 0.6          # threshold m√≠nimo de confian√ßa\n",
        "WINDOW_SEC = 10        # janela deslizante para features (segundos)\n",
        "\n",
        "# Par√¢metros para merge de basculamento\n",
        "MAX_SHORT_MOVE_SEC = 30.0    # dura√ß√£o m√°xima de movimento curto\n",
        "MAX_SHORT_MOVE_SPEED = 5.0   # velocidade m√°xima para movimento curto\n",
        "\n",
        "# Par√¢metros para prototipagem\n",
        "PROTOTYPE_DEVICES = None      # None = todos, ou lista ['TRK-101', ...]\n",
        "PROTOTYPE_DAYS = 1             # n√∫mero de dias para prototipar\n",
        "\n",
        "print(\"‚úÖ Par√¢metros configurados:\")\n",
        "print(f\"   V_STOP = {V_STOP} km/h\")\n",
        "print(f\"   MIN_STOP_SEC = {MIN_STOP_SEC} s\")\n",
        "print(f\"   GAP_SEC = {GAP_SEC} s\")\n",
        "print(f\"   TH_CONF = {TH_CONF}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 1: Schema Discovery e Conex√£o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descobrir schema do banco\n",
        "schema = discover_schema()\n",
        "print(\"\\nüìä Schema descoberto:\")\n",
        "for category, cols in schema.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for col in cols:\n",
        "        print(f\"  - {col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar disponibilidade de dados\n",
        "availability = check_data_availability()\n",
        "\n",
        "print(\"\\nüìÖ Disponibilidade de Dados:\")\n",
        "print(f\"   Primeiro registro: {availability['min_time']}\")\n",
        "print(f\"   √öltimo registro:   {availability['max_time']}\")\n",
        "print(f\"   Total de registros: {availability['total_records']:,}\")\n",
        "print(f\"\\nüì± Devices dispon√≠veis ({len(availability['devices'])}):\")\n",
        "for dev in availability['devices']:\n",
        "    print(f\"   - {dev}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Colunas cr√≠ticas dispon√≠veis:\")\n",
        "critical_cols = ['linear_accel_magnitude', 'pitch', 'roll', 'speed_kmh']\n",
        "for col in critical_cols:\n",
        "    status = \"‚úÖ\" if col in availability['available_columns'] else \"‚ùå\"\n",
        "    print(f\"   {status} {col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 2: Extra√ß√£o de Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecionar devices para prototipagem\n",
        "if PROTOTYPE_DEVICES is None:\n",
        "    device_ids = availability['devices'][:5]  # Primeiros 5 devices\n",
        "    print(f\"üì± Selecionando primeiros {len(device_ids)} devices para prototipagem\")\n",
        "else:\n",
        "    device_ids = PROTOTYPE_DEVICES\n",
        "    print(f\"üì± Usando devices especificados: {device_ids}\")\n",
        "\n",
        "print(f\"\\nDevices: {device_ids}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir per√≠odo de consulta\n",
        "t_end = availability['max_time']\n",
        "t_start = t_end - timedelta(days=PROTOTYPE_DAYS)\n",
        "\n",
        "print(f\"\\nüìÖ Per√≠odo de consulta:\")\n",
        "print(f\"   In√≠cio: {t_start}\")\n",
        "print(f\"   Fim:    {t_end}\")\n",
        "print(f\"   Dura√ß√£o: {(t_end - t_start).total_seconds() / 3600:.1f} horas\")\n",
        "\n",
        "# Carregar dados\n",
        "print(\"\\n‚è≥ Carregando dados do banco...\")\n",
        "df = query_data(device_ids, t_start, t_end)\n",
        "\n",
        "print(f\"\\n‚úÖ Dados carregados:\")\n",
        "print(f\"   Registros: {len(df):,}\")\n",
        "print(f\"   Devices: {df['device_id'].nunique()}\")\n",
        "print(f\"   Per√≠odo: {df['time'].min()} at√© {df['time'].max()}\")\n",
        "print(f\"\\nüìä Colunas dispon√≠veis:\")\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar qualidade dos dados\n",
        "print(\"\\nüîç Qualidade dos Dados:\")\n",
        "print(f\"\\nValores nulos por coluna cr√≠tica:\")\n",
        "critical_cols_check = ['speed_kmh', 'linear_accel_magnitude', 'pitch', 'roll']\n",
        "for col in critical_cols_check:\n",
        "    if col in df.columns:\n",
        "        null_count = df[col].isna().sum()\n",
        "        null_pct = (null_count / len(df)) * 100\n",
        "        print(f\"   {col}: {null_count:,} nulos ({null_pct:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"   {col}: ‚ùå COLUNA N√ÉO ENCONTRADA\")\n",
        "\n",
        "# Estat√≠sticas b√°sicas\n",
        "print(f\"\\nüìä Estat√≠sticas de velocidade:\")\n",
        "if 'speed_kmh' in df.columns:\n",
        "    print(df['speed_kmh'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 3: Segmenta√ß√£o de Estados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encontrar segmentos de parada\n",
        "print(\"üîç Identificando segmentos de parada...\")\n",
        "stop_segments = find_stop_segments(\n",
        "    df,\n",
        "    speed_col='speed_kmh',\n",
        "    v_stop=V_STOP,\n",
        "    min_stop_sec=MIN_STOP_SEC,\n",
        "    gap_sec=GAP_SEC\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Segmentos de parada encontrados: {len(stop_segments)}\")\n",
        "if len(stop_segments) > 0:\n",
        "    print(f\"\\nEstat√≠sticas:\")\n",
        "    print(stop_segments[['duration_s', 'is_stop']].describe())\n",
        "    print(f\"\\nPrimeiros segmentos:\")\n",
        "    print(stop_segments.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encontrar segmentos de movimento\n",
        "print(\"üîç Identificando segmentos de movimento...\")\n",
        "moving_segments = find_moving_segments(\n",
        "    df,\n",
        "    speed_col='speed_kmh',\n",
        "    v_stop=V_STOP\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Segmentos de movimento encontrados: {len(moving_segments)}\")\n",
        "if len(moving_segments) > 0:\n",
        "    print(f\"\\nEstat√≠sticas:\")\n",
        "    print(moving_segments[['duration_s', 'is_stop']].describe())\n",
        "    \n",
        "    # Estat√≠sticas de velocidade durante movimento\n",
        "    print(f\"\\nüìä Velocidade durante movimento:\")\n",
        "    for _, seg in moving_segments.head(5).iterrows():\n",
        "        seg_data = df[\n",
        "            (df['device_id'] == seg['device_id']) &\n",
        "            (df['time'] >= seg['t_start']) &\n",
        "            (df['time'] <= seg['t_end'])\n",
        "        ]\n",
        "        if not seg_data.empty and 'speed_kmh' in seg_data.columns:\n",
        "            avg_speed = seg_data['speed_kmh'].mean()\n",
        "            print(f\"   {seg['device_id']}: {avg_speed:.1f} km/h (dura√ß√£o: {seg['duration_s']:.1f}s)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge de basculamento com andadinha curta\n",
        "print(\"üîç Aplicando merge de basculamento com andadinha curta...\")\n",
        "\n",
        "merged_stop_segments = merge_basculamento_segments(\n",
        "    stop_segments,\n",
        "    moving_segments,\n",
        "    df,\n",
        "    max_short_move_sec=MAX_SHORT_MOVE_SEC,\n",
        "    max_short_move_speed=MAX_SHORT_MOVE_SPEED\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Merge aplicado\")\n",
        "if 'basculamento_merge' in merged_stop_segments.columns:\n",
        "    n_merged = merged_stop_segments['basculamento_merge'].sum()\n",
        "    print(f\"   Segmentos marcados para merge: {n_merged}\")\n",
        "\n",
        "# Usar segmentos mergeados daqui em diante\n",
        "final_stop_segments = merged_stop_segments.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 4: Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extrair features para cada segmento de parada\n",
        "print(\"üîß Extraindo features dos segmentos de parada...\")\n",
        "\n",
        "segments_with_features = []\n",
        "\n",
        "for idx, seg in final_stop_segments.iterrows():\n",
        "    # Obter dados do segmento\n",
        "    seg_data = df[\n",
        "        (df['device_id'] == seg['device_id']) &\n",
        "        (df['time'] >= seg['t_start']) &\n",
        "        (df['time'] <= seg['t_end'])\n",
        "    ].copy()\n",
        "    \n",
        "    if len(seg_data) < 2:\n",
        "        continue\n",
        "    \n",
        "    # Extrair features\n",
        "    features = extract_features(seg_data, window_sec=WINDOW_SEC)\n",
        "    \n",
        "    # Adicionar informa√ß√µes do segmento\n",
        "    seg_dict = seg.to_dict()\n",
        "    seg_dict.update(features)\n",
        "    \n",
        "    segments_with_features.append(seg_dict)\n",
        "\n",
        "segments_df = pd.DataFrame(segments_with_features)\n",
        "\n",
        "print(f\"\\n‚úÖ Features extra√≠das para {len(segments_df)} segmentos\")\n",
        "print(f\"\\nüìä Features dispon√≠veis ({len([c for c in segments_df.columns if c not in ['device_id', 't_start', 't_end', 'duration_s', 'is_stop']])}):\")\n",
        "feature_cols = [c for c in segments_df.columns if c not in ['device_id', 't_start', 't_end', 'duration_s', 'is_stop', 'basculamento_merge', 'merge_t_end']]\n",
        "for col in feature_cols[:20]:  # Mostrar primeiras 20\n",
        "    print(f\"   - {col}\")\n",
        "if len(feature_cols) > 20:\n",
        "    print(f\"   ... e mais {len(feature_cols) - 20} features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 5: Sistema de Rotulagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classificar cada segmento\n",
        "print(\"üè∑Ô∏è  Classificando segmentos...\")\n",
        "\n",
        "labeled_segments = []\n",
        "\n",
        "for idx, seg in segments_df.iterrows():\n",
        "    # Converter features para dict\n",
        "    features_dict = {}\n",
        "    for col in feature_cols:\n",
        "        if col in seg.index:\n",
        "            val = seg[col]\n",
        "            if pd.notna(val):\n",
        "                features_dict[col] = float(val)\n",
        "    \n",
        "    # Classificar\n",
        "    label, confidence, rule_trace = classify_stop_segment(features_dict, th_conf=TH_CONF)\n",
        "    \n",
        "    # Adicionar ao resultado\n",
        "    result = {\n",
        "        'device_id': seg['device_id'],\n",
        "        't_start': seg['t_start'],\n",
        "        't_end': seg['t_end'],\n",
        "        'duration_s': seg['duration_s'],\n",
        "        'is_moving': False,  # Todos s√£o paradas\n",
        "        'label': label,\n",
        "        'confidence': confidence,\n",
        "        'rule_trace': rule_trace\n",
        "    }\n",
        "    \n",
        "    # Adicionar features\n",
        "    result.update(features_dict)\n",
        "    \n",
        "    labeled_segments.append(result)\n",
        "\n",
        "labeled_df = pd.DataFrame(labeled_segments)\n",
        "\n",
        "print(f\"\\n‚úÖ Segmentos classificados: {len(labeled_df)}\")\n",
        "print(f\"\\nüìä Distribui√ß√£o de labels:\")\n",
        "print(labeled_df['label'].value_counts())\n",
        "print(f\"\\nüìä Confian√ßa m√©dia por label:\")\n",
        "print(labeled_df.groupby('label')['confidence'].agg(['mean', 'std', 'min', 'max']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adicionar segmentos de movimento ao dataset final\n",
        "print(\"üìä Adicionando segmentos de movimento...\")\n",
        "\n",
        "moving_labeled = []\n",
        "for idx, seg in moving_segments.iterrows():\n",
        "    moving_labeled.append({\n",
        "        'device_id': seg['device_id'],\n",
        "        't_start': seg['t_start'],\n",
        "        't_end': seg['t_end'],\n",
        "        'duration_s': seg['duration_s'],\n",
        "        'is_moving': True,\n",
        "        'label': 'MOVIMENTO',\n",
        "        'confidence': 1.0,\n",
        "        'rule_trace': 'Segmento de movimento (speed > V_STOP)'\n",
        "    })\n",
        "\n",
        "moving_df = pd.DataFrame(moving_labeled)\n",
        "\n",
        "# Combinar paradas e movimento\n",
        "final_labeled_df = pd.concat([labeled_df, moving_df], ignore_index=True)\n",
        "final_labeled_df = final_labeled_df.sort_values(['device_id', 't_start']).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset final criado: {len(final_labeled_df)} segmentos\")\n",
        "print(f\"\\nüìä Distribui√ß√£o final:\")\n",
        "print(final_labeled_df.groupby(['is_moving', 'label']).size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 6: Visualiza√ß√µes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Scatter: speed vs accel_magnitude\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "if 'speed_kmh' in df.columns and 'linear_accel_magnitude' in df.columns:\n",
        "    # Amostrar para visualiza√ß√£o (se muitos pontos)\n",
        "    plot_df = df.sample(min(10000, len(df))) if len(df) > 10000 else df\n",
        "    \n",
        "    # Colorir por tipo de segmento\n",
        "    plot_df['segment_type'] = 'unknown'\n",
        "    \n",
        "    for _, seg in final_labeled_df.iterrows():\n",
        "        mask = (\n",
        "            (plot_df['device_id'] == seg['device_id']) &\n",
        "            (plot_df['time'] >= seg['t_start']) &\n",
        "            (plot_df['time'] <= seg['t_end'])\n",
        "        )\n",
        "        plot_df.loc[mask, 'segment_type'] = seg['label']\n",
        "    \n",
        "    # Plot\n",
        "    for label in plot_df['segment_type'].unique():\n",
        "        if label != 'unknown':\n",
        "            data = plot_df[plot_df['segment_type'] == label]\n",
        "            ax.scatter(\n",
        "                data['speed_kmh'],\n",
        "                data['linear_accel_magnitude'],\n",
        "                label=label,\n",
        "                alpha=0.3,\n",
        "                s=10\n",
        "            )\n",
        "    \n",
        "    ax.axvline(V_STOP, color='red', linestyle='--', label=f'V_STOP={V_STOP} km/h')\n",
        "    ax.set_xlabel('Velocidade (km/h)')\n",
        "    ax.set_ylabel('Acelera√ß√£o Linear Magnitude (m/s¬≤)')\n",
        "    ax.set_title('Speed vs Acelera√ß√£o Linear - Segmentos Coloridos por Label')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Colunas necess√°rias n√£o encontradas para este gr√°fico\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Timeline por device com segmentos coloridos\n",
        "for device_id in final_labeled_df['device_id'].unique()[:3]:  # Primeiros 3 devices\n",
        "    device_data = df[df['device_id'] == device_id].copy()\n",
        "    device_segments = final_labeled_df[final_labeled_df['device_id'] == device_id]\n",
        "    \n",
        "    if device_data.empty:\n",
        "        continue\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True)\n",
        "    \n",
        "    # Plot 1: Velocidade\n",
        "    axes[0].plot(device_data['time'], device_data['speed_kmh'], 'b-', alpha=0.5, linewidth=0.5)\n",
        "    axes[0].axhline(V_STOP, color='r', linestyle='--', label=f'V_STOP={V_STOP}')\n",
        "    axes[0].set_ylabel('Velocidade (km/h)')\n",
        "    axes[0].set_title(f'Timeline - Device {device_id}')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Acelera√ß√£o\n",
        "    if 'linear_accel_magnitude' in device_data.columns:\n",
        "        axes[1].plot(device_data['time'], device_data['linear_accel_magnitude'], 'g-', alpha=0.5, linewidth=0.5)\n",
        "        axes[1].set_ylabel('Acelera√ß√£o Linear (m/s¬≤)')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Segmentos coloridos\n",
        "    colors_map = {\n",
        "        'CARREGAMENTO': 'orange',\n",
        "        'BASCULAMENTO': 'purple',\n",
        "        'MOTOR_LIGADO': 'green',\n",
        "        'MOTOR_DESLIGADO': 'gray',\n",
        "        'MOVIMENTO': 'blue',\n",
        "        'DESCONHECIDO': 'red'\n",
        "    }\n",
        "    \n",
        "    for _, seg in device_segments.iterrows():\n",
        "        color = colors_map.get(seg['label'], 'black')\n",
        "        axes[2].axvspan(seg['t_start'], seg['t_end'], alpha=0.3, color=color, label=seg['label'])\n",
        "    \n",
        "    axes[2].set_xlabel('Tempo')\n",
        "    axes[2].set_ylabel('Segmentos')\n",
        "    axes[2].set_title('Segmentos Rotulados')\n",
        "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Exemplos por classe\n",
        "print(\"üìä Exemplos de segmentos por classe:\")\n",
        "\n",
        "for label in labeled_df['label'].unique():\n",
        "    label_segments = labeled_df[labeled_df['label'] == label]\n",
        "    \n",
        "    if len(label_segments) == 0:\n",
        "        continue\n",
        "    \n",
        "    # Pegar exemplo com maior confian√ßa\n",
        "    example = label_segments.loc[label_segments['confidence'].idxmax()]\n",
        "    \n",
        "    seg_data = df[\n",
        "        (df['device_id'] == example['device_id']) &\n",
        "        (df['time'] >= example['t_start']) &\n",
        "        (df['time'] <= example['t_end'])\n",
        "    ].copy()\n",
        "    \n",
        "    if len(seg_data) < 2:\n",
        "        continue\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
        "    \n",
        "    # Plot acelera√ß√£o\n",
        "    if 'linear_accel_magnitude' in seg_data.columns:\n",
        "        axes[0].plot(seg_data['time'], seg_data['linear_accel_magnitude'], 'b-', linewidth=1)\n",
        "        \n",
        "        # Marcar picos\n",
        "        if 'peak_count' in example and example['peak_count'] > 0:\n",
        "            accel_vals = seg_data['linear_accel_magnitude'].values\n",
        "            from scipy import signal\n",
        "            peaks, _ = signal.find_peaks(\n",
        "                accel_vals,\n",
        "                height=accel_vals.mean() + accel_vals.std()\n",
        "            )\n",
        "            axes[0].plot(seg_data['time'].iloc[peaks], accel_vals[peaks], 'ro', markersize=8, label='Picos')\n",
        "        \n",
        "        axes[0].set_ylabel('Acelera√ß√£o Linear (m/s¬≤)')\n",
        "        axes[0].set_title(f\"Exemplo: {label} (Confian√ßa: {example['confidence']:.2f})\")\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot pitch\n",
        "    if 'pitch' in seg_data.columns:\n",
        "        axes[1].plot(seg_data['time'], seg_data['pitch'], 'g-', linewidth=1)\n",
        "        axes[1].set_ylabel('Pitch (graus)')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot roll\n",
        "    if 'roll' in seg_data.columns:\n",
        "        axes[2].plot(seg_data['time'], seg_data['roll'], 'r-', linewidth=1)\n",
        "        axes[2].set_ylabel('Roll (graus)')\n",
        "        axes[2].set_xlabel('Tempo')\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Adicionar trace de regras\n",
        "    fig.suptitle(f\"{label} - {example['rule_trace'][:100]}...\", fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n{label}: {example['rule_trace']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Distribui√ß√£o de features por classe\n",
        "feature_cols_to_plot = ['accel_mean', 'accel_std', 'accel_rms', 'peak_count', 'pitch_delta_total']\n",
        "available_feature_cols = [c for c in feature_cols_to_plot if c in labeled_df.columns]\n",
        "\n",
        "if len(available_feature_cols) > 0:\n",
        "    n_cols = min(3, len(available_feature_cols))\n",
        "    n_rows = (len(available_feature_cols) + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 5*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feat_col in enumerate(available_feature_cols):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Boxplot por label\n",
        "        data_to_plot = []\n",
        "        labels_list = []\n",
        "        \n",
        "        for label in labeled_df['label'].unique():\n",
        "            label_data = labeled_df[labeled_df['label'] == label][feat_col].dropna()\n",
        "            if len(label_data) > 0:\n",
        "                data_to_plot.append(label_data.values)\n",
        "                labels_list.append(label)\n",
        "        \n",
        "        if len(data_to_plot) > 0:\n",
        "            ax.boxplot(data_to_plot, labels=labels_list)\n",
        "            ax.set_ylabel(feat_col)\n",
        "            ax.set_title(f'Distribui√ß√£o de {feat_col} por Label')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ocultar eixos extras\n",
        "    for idx in range(len(available_feature_cols), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Features n√£o dispon√≠veis para plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 7: Clustering Explorat√≥rio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar dados para clustering\n",
        "print(\"üîç Preparando dados para clustering...\")\n",
        "\n",
        "# Selecionar features num√©ricas relevantes\n",
        "clustering_features = [\n",
        "    'accel_mean', 'accel_std', 'accel_rms', 'accel_energy',\n",
        "    'peak_count', 'peak_height_mean',\n",
        "    'pitch_mean', 'pitch_std', 'pitch_delta_total',\n",
        "    'roll_mean', 'roll_std',\n",
        "    'energy_ratio_low', 'energy_ratio_high'\n",
        "]\n",
        "\n",
        "available_clustering_features = [c for c in clustering_features if c in labeled_df.columns]\n",
        "\n",
        "if len(available_clustering_features) < 3:\n",
        "    print(\"‚ö†Ô∏è Features insuficientes para clustering\")\n",
        "else:\n",
        "    print(f\"‚úÖ Usando {len(available_clustering_features)} features para clustering\")\n",
        "    \n",
        "    # Preparar matriz\n",
        "    X = labeled_df[available_clustering_features].fillna(0).values\n",
        "    \n",
        "    # Normalizar\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    # HDBSCAN\n",
        "    try:\n",
        "        import hdbscan\n",
        "        \n",
        "        print(\"\\nüîç Executando HDBSCAN...\")\n",
        "        clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=2)\n",
        "        cluster_labels = clusterer.fit_predict(X_scaled)\n",
        "        \n",
        "        labeled_df['cluster'] = cluster_labels\n",
        "        \n",
        "        print(f\"\\n‚úÖ Clustering conclu√≠do:\")\n",
        "        print(f\"   Clusters encontrados: {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)}\")\n",
        "        print(f\"   Ru√≠do (cluster -1): {(cluster_labels == -1).sum()}\")\n",
        "        print(f\"\\nüìä Distribui√ß√£o de clusters:\")\n",
        "        print(pd.Series(cluster_labels).value_counts().sort_index())\n",
        "        \n",
        "        # Comparar clusters vs labels\n",
        "        print(f\"\\nüìä Compara√ß√£o Clusters vs Labels:\")\n",
        "        comparison = pd.crosstab(labeled_df['label'], labeled_df['cluster'])\n",
        "        print(comparison)\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è HDBSCAN n√£o instalado. Tentando KMeans...\")\n",
        "        \n",
        "        from sklearn.cluster import KMeans\n",
        "        \n",
        "        n_clusters = min(5, len(labeled_df) // 3)\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "        \n",
        "        labeled_df['cluster'] = cluster_labels\n",
        "        \n",
        "        print(f\"\\n‚úÖ KMeans conclu√≠do com {n_clusters} clusters\")\n",
        "        print(f\"\\nüìä Compara√ß√£o Clusters vs Labels:\")\n",
        "        comparison = pd.crosstab(labeled_df['label'], labeled_df['cluster'])\n",
        "        print(comparison)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o de clusters (se tiver 2+ features)\n",
        "if 'cluster' in labeled_df.columns and len(available_clustering_features) >= 2:\n",
        "    from sklearn.decomposition import PCA\n",
        "    \n",
        "    # Reduzir para 2D com PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(X_scaled)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Plot 1: Por cluster\n",
        "    scatter1 = axes[0].scatter(X_2d[:, 0], X_2d[:, 1], c=labeled_df['cluster'], cmap='tab10', alpha=0.6)\n",
        "    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "    axes[0].set_title('Clusters (HDBSCAN/KMeans)')\n",
        "    plt.colorbar(scatter1, ax=axes[0])\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Por label\n",
        "    label_map = {label: idx for idx, label in enumerate(labeled_df['label'].unique())}\n",
        "    label_colors = labeled_df['label'].map(label_map)\n",
        "    scatter2 = axes[1].scatter(X_2d[:, 0], X_2d[:, 1], c=label_colors, cmap='Set1', alpha=0.6)\n",
        "    axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "    axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "    axes[1].set_title('Labels (Regras)')\n",
        "    plt.colorbar(scatter2, ax=axes[1])\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìä Vari√¢ncia explicada por PC: {pca.explained_variance_ratio_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C√©lula 8: Export e Persist√™ncia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar dataset final para export\n",
        "print(\"üíæ Preparando export...\")\n",
        "\n",
        "# Selecionar colunas principais\n",
        "export_cols = [\n",
        "    'device_id', 't_start', 't_end', 'duration_s', 'is_moving',\n",
        "    'label', 'confidence', 'rule_trace'\n",
        "]\n",
        "\n",
        "# Adicionar features dispon√≠veis\n",
        "feature_export_cols = [c for c in final_labeled_df.columns if c not in export_cols]\n",
        "export_cols_final = export_cols + feature_export_cols\n",
        "\n",
        "export_df = final_labeled_df[export_cols_final].copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset preparado: {len(export_df)} segmentos, {len(export_cols_final)} colunas\")\n",
        "print(f\"\\nColunas principais:\")\n",
        "for col in export_cols:\n",
        "    print(f\"   - {col}\")\n",
        "print(f\"\\n... e {len(feature_export_cols)} features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar em Parquet\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "output_dir = 'labeled_segments'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "parquet_path = os.path.join(output_dir, f'labeled_segments_{timestamp_str}.parquet')\n",
        "csv_path = os.path.join(output_dir, f'labeled_segments_{timestamp_str}.csv')\n",
        "\n",
        "export_df.to_parquet(parquet_path, index=False)\n",
        "export_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Arquivos salvos:\")\n",
        "print(f\"   Parquet: {parquet_path}\")\n",
        "print(f\"   CSV:     {csv_path}\")\n",
        "print(f\"\\nüìä Estat√≠sticas finais:\")\n",
        "print(f\"   Total de segmentos: {len(export_df)}\")\n",
        "print(f\"   Paradas rotuladas: {len(export_df[~export_df['is_moving']])}\")\n",
        "print(f\"   Movimento: {len(export_df[export_df['is_moving']])}\")\n",
        "print(f\"\\nüìä Distribui√ß√£o de labels:\")\n",
        "print(export_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumo final\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESUMO DO PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n‚úÖ Segmentos processados: {len(export_df)}\")\n",
        "print(f\"‚úÖ Paradas rotuladas: {len(export_df[~export_df['is_moving']])}\")\n",
        "print(f\"‚úÖ Movimento: {len(export_df[export_df['is_moving']])}\")\n",
        "print(f\"\\nüìä Labels encontrados:\")\n",
        "for label, count in export_df['label'].value_counts().items():\n",
        "    pct = (count / len(export_df)) * 100\n",
        "    print(f\"   {label}: {count} ({pct:.1f}%)\")\n",
        "print(f\"\\nüìä Confian√ßa m√©dia: {export_df['confidence'].mean():.2f}\")\n",
        "print(f\"üìä Confian√ßa m√≠nima: {export_df['confidence'].min():.2f}\")\n",
        "print(f\"\\nüíæ Arquivos salvos em: {output_dir}/\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
